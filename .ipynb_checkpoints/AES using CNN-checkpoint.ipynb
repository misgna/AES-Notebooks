{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a21710e-d41d-40fd-b304-dd645ec83667",
   "metadata": {},
   "source": [
    "# Automated essay scoring using CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7c190391-a425-4f31-a99b-f25a39061537",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import Counter\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2f9b1a80-d9b7-438a-9748-5c23bde9c446",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/astra/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/astra/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')      # For tokenization\n",
    "nltk.download('stopwords')  # For stopwords\n",
    "\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "46e096a8-f007-4e5c-a807-6abc4519779c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Set the random seed for CPU\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Set the random seed for GPU (if using CUDA)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "    torch.cuda.manual_seed_all(42)  # If you are using multiple GPUs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41fdc4b-04c6-4429-8f7f-b4cd59e36a84",
   "metadata": {},
   "source": [
    "## Load dataset\n",
    "In this notebook, we are going to use the [ASAP-AES](https://www.kaggle.com/competitions/asap-aes) dataset for modeling a CNN-based essay scoring. In order to compare our results with other research works, we will load the Taghipour and Ng (2016) five-fold cross validation. Please read their [paper](https://aclanthology.org/D16-1193.pdf) for details about the dataset and the split. In addition, this work is one of the earliest research on the employment of neural networks for AES tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cd031b9-da54-40af-9d8e-87ec374a3352",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'asap_5cv'\n",
    "folds_data = []\n",
    "\n",
    "for idx in range(0,5):   \n",
    "    train_data = pd.read_csv(os.path.join(filepath, f'fold_{idx}', f'train.tsv'), sep='\\t', encoding='ISO-8859-1')\n",
    "    dev_data = pd.read_csv(os.path.join(filepath, f'fold_{idx}', f'dev.tsv'), sep='\\t', encoding='ISO-8859-1')\n",
    "    test_data = pd.read_csv(os.path.join(filepath, f'fold_{idx}', f'test.tsv'), sep='\\t', encoding='ISO-8859-1')\n",
    "        \n",
    "    folds_data.append((train_data, dev_data, test_data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e87efc-f787-4b56-a698-e9eaa10040d2",
   "metadata": {},
   "source": [
    "### Preprocessing of the essay and normalizing the scores.\n",
    "The ASAP-AES dataset contains essays, scores, essay prompts and other more fields. The essay prompt (essay_set) is the prompt (question) where it is represented using numbers. In the dataset, there are 8 prompts and each prompt has its own score range. Therefore, we will apply min-max normalization to change the score range into 0-1. Besides this, we are dealing with text input, therefore, we will apply text preprocessing as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "28f70791-226c-451c-903c-ac1440f51d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {\n",
    "        1: (2, 12),\n",
    "        2: (1, 6),\n",
    "        3: (0, 3),\n",
    "        4: (0, 3),\n",
    "        5: (0, 4),\n",
    "        6: (0, 4),\n",
    "        7: (0, 30),\n",
    "        8: (0, 60)\n",
    "    }\n",
    "def normalize_score(scores):\n",
    "    return (scores - scores.min()) / (scores.max() - scores.min())\n",
    "    \n",
    "def prompt_score(score, prompt):\n",
    "    return round(score * (scores[prompt][1] - scores[prompt][0]) + scores[prompt][0])\n",
    "\n",
    "def create_vocab(essays, top_n):\n",
    "    #preprocess essays\n",
    "    essays = essays.lower()\n",
    "    essays = essays.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Tokenize the collection\n",
    "    tokens = word_tokenize(essays)\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    # Token distribution\n",
    "    token_dist = Counter(tokens)\n",
    "    frequent_tokens = token_dist.most_common(top_n)\n",
    "    # Select tokens\n",
    "    tokens_4_vocab = [token for (token, freq) in frequent_tokens]\n",
    "    # Index tokens    \n",
    "    vocab = {'<pad>':0, '<unk>':1, '<num>':2}\n",
    "    for word in tokens_4_vocab:\n",
    "        vocab[word] = len(vocab)\n",
    "    #vocab = {word: i + len(vocab) for i, word in enumerate(tokens_4_vocab)}\n",
    "    \n",
    "    return vocab\n",
    "def encode_essay(text, vocab):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    enc_essay = []\n",
    "    for token in tokens:\n",
    "        if token.isdigit():\n",
    "            enc_essay.append(vocab['<num>'])\n",
    "        elif token in vocab:\n",
    "            enc_essay.append(vocab[token])\n",
    "        else:\n",
    "            enc_essay.append(vocab['<unk>'])\n",
    "    return enc_essay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "caa2d7a4-ddf4-4a79-ad78-6265270e5135",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (train, dev, test) in folds_data:\n",
    "    # Min-Max Normalization\n",
    "    train['normalized_score'] = train.groupby('essay_set')['domain1_score'].transform(normalize_score)\n",
    "    dev['normalized_score'] = dev.groupby('essay_set')['domain1_score'].transform(normalize_score)\n",
    "    test['normalized_score'] = test.groupby('essay_set')['domain1_score'].transform(normalize_score)\n",
    "\n",
    "    # encode essay\n",
    "    # create vocab with vocab size = 4000\n",
    "    top_n = 4000\n",
    "    vocab = create_vocab(str(train['essay'].tolist()), top_n)\n",
    "    train['encoded_essay'] = train['essay'].apply(encode_essay, args=(vocab, ))\n",
    "    dev['encoded_essay'] = dev['essay'].apply(encode_essay, args=(vocab, ))\n",
    "    test['encoded_essay'] = test['essay'].apply(encode_essay, args=(vocab, ))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9524d43-2d3c-49e6-8dca-93d7026a9bc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "67e43196-2427-4a80-ad93-1fc544c5c6bd",
   "metadata": {},
   "source": [
    "## Custom Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a9ed49ba-3d65-4c97-b5d2-22ecd7d095d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data.iloc[idx]\n",
    "        normalized_score = sample['normalized_score'] #normalized score\n",
    "        domain_score = sample['domain1_score'] #domain1 score\n",
    "        essay = sample['encoded_essay']\n",
    "        \n",
    "        \n",
    "        return essay, normalized_score, domain_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06eafd66-f13c-44c2-b2c4-8ddb393982a4",
   "metadata": {},
   "source": [
    "## The model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ef2d195c-7b26-43af-996d-84f4b441a8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNAES(nn.Module):\n",
    "    def __init__(self, embedding_dim, vocab_size, hidden_dim, num_classes):\n",
    "        super().__init__()\n",
    "        #self.embedding = nn.Embedding.from_pretrained(pretrained_embeddings, freeze=True)\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.cnn=nn.Conv1d(embedding_dim, hidden_dim, kernel_size=3, padding=1)\n",
    "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, essay):\n",
    "        output = self.embedding(essay)\n",
    "        output = self.cnn(output.transpose(1, 2))\n",
    "        output = output.transpose(1,2)\n",
    "        output = self.relu(output)\n",
    "        output = self.dropout(output)\n",
    "        output = torch.mean(output, dim=1)\n",
    "        output = self.fc(output)\n",
    "        \n",
    "        return self.sigmoid(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9cabd8-aa16-4e6c-96ef-343e2c920733",
   "metadata": {},
   "source": [
    "## Training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "de1b094a-4fda-45eb-850b-f6b4cb2b89ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "def training(model, data, optimizer, loss_fn):\n",
    "    model.train()\n",
    "    loss = 0.0\n",
    "    for (essays, scores, d_scores) in data:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(essays.to(DEVICE))\n",
    "        scores = scores.reshape(-1, 1)\n",
    "        loss = loss_fn(output, scores.to(DEVICE))\n",
    "        loss.backward()\n",
    "        # Apply gradient clipping (Max norm = 10.0) as Taghipour and Ng (2016)\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=10.0)\n",
    "        optimizer.step()\n",
    "\n",
    "# Tune hyperparameters and monitor performance\n",
    "def validation(model, data, loss_fn):\n",
    "    model.eval()\n",
    "    qwk = 0\n",
    "    mse_loss = 0\n",
    "    val_output, val_score, val_n_scores = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for (essays, scores, d_scores) in data:\n",
    "            output = model(essays.to(DEVICE))\n",
    "            output = torch.tensor([out.item() for out in output], dtype=torch.float32)\n",
    "            output = output.reshape(-1, 1)\n",
    "\n",
    "            d_scores = d_scores.reshape(-1, 1)\n",
    "            loss = loss_fn(output, d_scores)\n",
    "            mse_loss += loss\n",
    "            val_output.extend(output.flatten().tolist())\n",
    "            val_score.extend(d_scores.flatten().tolist())\n",
    "\n",
    "    return val_output, val_score, mse_loss, model.state_dict() \n",
    "\n",
    "# Tune hyperparameters and monitor performance\n",
    "def testing(model, best_state, data):\n",
    "    model.load_state_dict(best_state)\n",
    "    val_output, val_score, val_n_scores = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for (essays, scores, d_scores) in data:\n",
    "            output = model(essays.to(DEVICE))\n",
    "            output = torch.tensor([out.item() for out in output], dtype=torch.float32)\n",
    "            output = output.reshape(-1, 1)\n",
    "\n",
    "            d_scores = d_scores.reshape(-1, 1)\n",
    "            val_output.extend(output.flatten().tolist())\n",
    "            val_score.extend(d_scores.flatten().tolist())\n",
    "\n",
    "    return val_output, val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5aebfd-d9a5-4f1e-8b36-10638d40d3ee",
   "metadata": {},
   "source": [
    "## Other functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a0bdd90b-0f4d-4d54-b870-3c86f861fdce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    essays, nscores, dscores = zip(*batch)\n",
    "    max_length = max([len(entry) for entry in essays])\n",
    "    padded_essays = []\n",
    "    for tokens in essays:\n",
    "        padded_essay = tokens + [0] * (max_length - len(tokens))\n",
    "        padded_essays.append(padded_essay)\n",
    "    return torch.tensor(padded_essays, dtype=torch.int32), torch.tensor(nscores, dtype=torch.float32), torch.tensor(dscores, dtype=torch.int32)\n",
    "\n",
    "def evaluate_qwk(outputs, scores, prompt):\n",
    "    outputs = [int(prompt_score(out, prompt)) for out in outputs]\n",
    "    scores = [score for score  in scores] \n",
    "    \n",
    "    return cohen_kappa_score(outputs, scores, weights='quadratic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "eb13acb7-7e9d-4298-b07f-1cde5ac439f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 4000\n",
    "embedding_dim = 50\n",
    "hidden_dim = 100\n",
    "batch_size = 8\n",
    "target = 1\n",
    "epochs = 5\n",
    "# loss function\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5173406-f6fc-4a92-854d-73e93f9e2dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for prompt in range(1, 9):\n",
    "    for (train, dev, test) in folds_data:\n",
    "    \n",
    "        # Dataloader\n",
    "        train_ds = CustomDataset(train[train['essay_set'] == prompt])\n",
    "        val_ds = CustomDataset(dev[dev['essay_set'] == prompt])\n",
    "        test_ds = CustomDataset(test[test['essay_set'] == prompt])\n",
    "\n",
    "        train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "        val_dl = DataLoader(val_ds, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "        test_dl = DataLoader(test_ds, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "        # Call model\n",
    "        model = CNNAES(embedding_dim, vocab_size, hidden_dim, target)\n",
    "        model.to(DEVICE)\n",
    "        \n",
    "        # optimizer\n",
    "        optimizer = torch.optim.RMSprop(model.parameters(), lr=0.00004, alpha=0.9)\n",
    "    \n",
    "        best_model_state = None\n",
    "        \n",
    "        for epoch in range(0, epochs):\n",
    "            training(model, train_dl, optimizer, loss_fn)\n",
    "            outputs, scores, mse_loss, model_state =  validation(model, val_dl, loss_fn)\n",
    "\n",
    "            val_qwk = evaluate_qwk(outputs, scores, prompt)\n",
    "            \n",
    "            if best_model_state == None:\n",
    "                best_model_state = model_state\n",
    "                qwk = val_qwk\n",
    "                loss = mse_loss\n",
    "            else:\n",
    "                if val_qwk > qwk:\n",
    "                    best_model_state = model_state\n",
    "      \n",
    "        outputs, scores= testing(model, best_model_state, test_dl)\n",
    "        test_qwks.append(evaluate_qwk(outputs, scores, prompt))\n",
    "\n",
    "    # Display test in each validation fold \n",
    "    print('Prompt: ', prompt)\n",
    "    for idx in range(0, len(test_qwks)):\n",
    "        print(f'Fold {idx}: {test_qwks[idx]:.3f}')\n",
    "\n",
    "    # Display average qwk\n",
    "    avg_qwks = sum(test_qwks)/len(test_qwks)\n",
    "    print(f'Max qwks: {max(test_qwks):.3f}')\n",
    "    print(f'Avg qwks: {avg_qwks: .3f}')\n",
    "    print('-' * 20) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b3577b-3e50-4b0c-8006-6fffbdeb710a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
